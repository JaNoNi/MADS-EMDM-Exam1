{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c956-bdc7-405f-89bb-73656f14b7bb",
   "metadata": {},
   "source": [
    "# Elective Module Advanced Topics of Data Mining.\n",
    "---\n",
    "<b>MADS-EMDM Portfolio-Exam Part 1<br>\n",
    "Janosch H√∂fer, 938969</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c21e64-cf43-466b-87d1-0d211e1b06c3",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Introduction](#intro) <br>\n",
    "- [1. Exercise](#ex1) <br>\n",
    "- [2. Exercise](#ex2) <br>\n",
    "- [3. Exercise](#ex3) <br>\n",
    "- [4. Exercise](#ex4) <br>\n",
    "- [5. Exercise](#ex5)<br>\n",
    "- [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45565406-0b20-4068-9147-9ad734714b8b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "bla<br>\n",
    "Using [[1]](http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f2b17-b3b1-4f94-8a56-2bd201616743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Own classes and functions\n",
    "from helper_scripts.data_manipulation import setup_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb875a5-27c3-44cd-972b-239a85a220d1",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ex1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a6311-f408-4997-bcd4-e84bd851164b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Exercise\n",
    "\n",
    "Consider the following set of items: a, b, c, d, e, g, m in some transaction database. Assume that\n",
    "<b>APRIORI</b> is running and has already computed the set ùêø4 using alphabetical order on the items. The\n",
    "resulting set is:\n",
    "$$\n",
    "L_4 = \\begin{equation}\n",
    "\\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\{a, b, c, d\\}, \\{a, b, c, e\\}, \\{a, b, c, m\\}, \\{a, b, d, e\\}, \\{a, b, e, m\\} \\\\\n",
    "        \\{a, c, e, m\\}, \\{a, d, g, m\\}, \\{b, c, d, e\\}, \\{b, c, d, g\\}, \\{b, c, d, m\\} \\\\\n",
    "        \\{b, c, e, g\\}, \\{b, c, e, m\\}, \\{b, d, e, g\\}, \\{c, d, e, g\\}, \\{c, d, g, m\\} \\\\\n",
    "    \\end{aligned}\n",
    "    \\right\\}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509bac9-b43c-41df-b962-df7893b6d5ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbfc25e5-e7e3-414e-954f-b03c9aef1275",
   "metadata": {},
   "source": [
    "### 1.1. Use the APRIORI candidate generation (and alphabetical order on the items) to create the set $C_5$ of candidates for 5-element frequent itemsets. Explain your decisions to create or discard elements.\n",
    "\n",
    "bla\n",
    "$$\n",
    "C_5 = \\begin{equation}\n",
    "\\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\{a, b, c, d, e\\}, \\{b, c, d, e, g\\}, \\{b, c, d, e, m\\}, \\{b, c, d, g, m\\}, \\{b, c, e, g, m\\}\n",
    "    \\end{aligned}\n",
    "    \\right\\}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65dd9b5-8fdf-4670-8420-ba9c32ba2644",
   "metadata": {},
   "source": [
    "### 1.2. For how many itemsets does the database have to be scanned to yield $L_5$ from $C_5$?\n",
    "\n",
    "Only 1, because all the other itemsets can be removed beforehand,\"because at least one of their sets is not present in $C_5$.\n",
    "$$\n",
    "L_5 = \\begin{equation}\n",
    "\\left\\{\n",
    "    \\begin{aligned}\n",
    "        \\{b, c, d, e, m\\}\n",
    "    \\end{aligned}\n",
    "    \\right\\}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d98730-fa67-4cf2-a136-0455839786d2",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ex2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f4244e-27b7-4193-bfbd-b2126c9d0085",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eed311-32b4-4520-bf12-11a11bf258e5",
   "metadata": {},
   "source": [
    "### 2.1. Create the following grocery dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6b201-7962-4995-b011-aa5b842c03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = [\n",
    "    [\n",
    "        \"fish\",\n",
    "        \"apples\",\n",
    "        \"cider\",\n",
    "        \"dragon fruit\",\n",
    "        \"garlic\",\n",
    "        \"ice cream\",\n",
    "        \"mints\",\n",
    "        \"prunes\",\n",
    "    ],\n",
    "    [\"apples\", \"bacon\", \"cider\", \"fish\", \"lemons\", \"mints\", \"oatmeal\"],\n",
    "    [\"bacon\", \"fish\", \"ham\", \"jam\", \"oatmeal\"],\n",
    "    [\"bacon\", \"cider\", \"kiwis\", \"spam\", \"prunes\"],\n",
    "    [\"apples\", \"fish\", \"cider\", \"eggs\", \"lemons\", \"prunes\", \"mints\", \"nachos\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d503f-6970-40fd-9b07-a0326f7cbb3c",
   "metadata": {},
   "source": [
    "### 2.2. Load the dataset T10I4D100K from the Frequent Itemset Mining Dataset Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38414b-9f84-4bc6-9644-554b4f236042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "filename_data = \"T10I4D100K.dat\"\n",
    "data_url = \"http://fimi.uantwerpen.be/data\"\n",
    "path_to_data = \"data\"\n",
    "\n",
    "setup_raw_data(f\"{data_url}/{filename_data}\", path_to_data, filename_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf29f6-3dcf-4a57-9f09-396d65ac9af9",
   "metadata": {},
   "source": [
    "After downloading the data file, we must first bring it into the right format. First we split each row of text. Here it is important to remove the last entry in the list which is empty. This empty entry is the result of the method used, as can be seen in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92a5e4-84db-4c86-991c-c0cfbecd6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"test\\n\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f5bb3-8715-467d-ac5a-4fb7be520c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_to_data, filename_data), \"r\") as file:\n",
    "    dataset2_raw = file.read().split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4dc82e-49f5-46d6-94f0-6f4129cc23fb",
   "metadata": {},
   "source": [
    "Next we split each row into the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977cacc-da41-42e3-ad16-dd9943d32234",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_raw[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ea5d3-312a-4831-a623-a978db2fb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_long = [item.rstrip().split(\" \") for item in dataset2_raw]\n",
    "len(dataset2_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c18ae-ae28-427c-9f94-480a9412aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset2_long[:10000]\n",
    "len(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6267a-a788-44a0-bb37-93a44668cdc2",
   "metadata": {},
   "source": [
    "### 2.3. For each dataset compute the highest (relative) support that a non-empty itemset actually reaches.\n",
    "\n",
    "Before we can calculate the support, we must encode the transactions. For that we use the TransactionEncoder provided by the <i>mlxtend</i> library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b645514-232a-41d2-b722-53f7d174684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(dataset: list[list], sparse: bool = False) -> pd:\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit_transform(dataset, sparse=sparse)\n",
    "    if sparse:\n",
    "        return pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "    return pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998a796-7bd1-448f-8bc6-daebfa0a35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = encode_data(dataset1)\n",
    "data2 = encode_data(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa462bba-e3ce-4c53-89de-5d473805e351",
   "metadata": {},
   "source": [
    "With the encoded transactions, we are able to count the number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ac1cc-45c5-43da-a2a8-7d08886430fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e6421-f662-4211-a20a-63d5e4eedbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relsup_str = \"relativ_support\"\n",
    "pd.DataFrame(data1.sum() / data1.shape[0], columns=[relsup_str]).nlargest(5, relsup_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ebbc8-4cb1-4b80-a996-c053a1e72131",
   "metadata": {},
   "source": [
    "The highest relative support for dataset1 is 0.8 for the itemsets $\\{cider\\}$ and $\\{fish\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5afdfa-38d6-4168-b735-20d8a94a4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data2.sum() / data2.shape[0], columns=[relsup_str]).nlargest(5, relsup_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f9333-5e95-4277-9bc3-b32dfc2b7476",
   "metadata": {},
   "source": [
    "The highest relative support for dataset2 is 0.07828 for the itemset $\\{368\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce3eafc-7803-40b0-bc30-45d3f3a6836a",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ex3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d331f6-088f-4ef5-b3e9-d219c8efac0f",
   "metadata": {},
   "source": [
    "## 3. Exercise\n",
    "\n",
    "### 3.1. Run and time APRIORI once on the grocery dataset using a support threshold of 0.4 and a fitting line magic command. How long did the run take? How many frequent itemsets were found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b80cf-f619-49d1-8189-2ba925d95b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -o -q -n 1 -r 1\n",
    "\n",
    "df1_apriori = apriori(data1, min_support=0.4, use_colnames=True)\n",
    "print(f\"The command found {df1_apriori.shape[0]} frequent itemsets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1665938-eea5-4e1b-a0cd-13f358ae1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"And it ran for {_.average * 100:0.2f} milliseconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f52e70-6e9b-4cfe-aced-2d34245c0157",
   "metadata": {},
   "source": [
    "### 3.2. Run and time APRIORI once on the T10I4D100K dataset using a support threshold of 0.004 and a fitting line magic command. How long did the run take? How many frequent itemsets were found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb512f-5bb4-4ea1-ac9c-6c63a2ce374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -o -q -n 1 -r 1\n",
    "df2_apriori = apriori(data2, min_support=0.004, use_colnames=True)\n",
    "print(f\"The command found {df2_apriori.shape[0]} frequent itemsets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754d57c-be05-46d9-8874-062e6e9592bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"And it ran for {_.average:0.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7ea75-85dd-442f-bf9d-2df964a2df7b",
   "metadata": {},
   "source": [
    "### 3.3. Time repeated runs of APRIORI on both datasets using the above respective support thresholds and a fitting line magic command where:\n",
    "\n",
    "- on the grocery dataset, 10 measurements are taken, each relying on 10 executions\n",
    "- on the T10I4D100K dataset, 10 measurements are taken, each relying on 1 execution.\n",
    "\n",
    "Report average runtime together with standard deviation for both experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d8d36-4803-4039-9f62-8cd85fd64e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877b86b-c34d-43c2-87a2-697141e6507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -o -n 10 -r 10 apriori(data1, min_support=0.4, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7faa6-95c2-4a19-8413-e275481a645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit_results[\"Grocery_Dataset\"] = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575437c0-3b38-412c-91a7-a3678a07bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -o -n 1 -r 10 apriori(data2, min_support=0.004, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b03d24-a5d7-4f57-8180-6031dd08b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit_results[\"T10I4D100K\"] = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054fc66-7663-474c-959c-7fef647e9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, timit_res in timeit_results.items():\n",
    "    print(f\"Results for '{key}':\")\n",
    "    print(\n",
    "        f\"The command ran on average for {timit_res.average:0.5f}\"\n",
    "        f\" seconds and has a standard deviation of {timit_res.stdev:0.10f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd60232-d9e1-429d-8e12-361f68e5aeaa",
   "metadata": {},
   "source": [
    "#### 3.4. Discuss limitations of the above approaches!\n",
    "\n",
    "- Terrible to use with a good linter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ee455-bd2a-4387-b7ea-cf720b0f7123",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ex4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc48f3-afc8-41f8-b7cc-2b201bb40bd1",
   "metadata": {},
   "source": [
    "## 4. Exercise\n",
    "\n",
    "### 4.1. Time and run APRIORI on both datasets, first on the regular (non-sparse) representation, then on a sparse representation.\n",
    "\n",
    "- For the grocery dataset use 0.2, 0.4, 0.6, 0.8 as the support thresholds, run 10 measurements for each setting and use 10 executions for each measurement.\n",
    "- For the T10I4D100K dataset use 0.002, 0.004, 0.008, 0.016, 0.032, 0.064 as the support thresholds, run 10 measurements for each setting and use 1 execution for each repetition.\n",
    "\n",
    "Out of the 10 measurements, report only the minimum for each setting (column parameter and\n",
    "support threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb3826-ca94-41c0-8133-8a7e88024b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_time(func: callable, n_mes: int, n_exec: int, func_kwargs: dict) -> tuple[int, float]:\n",
    "    part_func = functools.partial(func, **func_kwargs)\n",
    "    results = timeit.repeat(part_func, repeat=n_mes, number=n_exec)\n",
    "    min_time = min(results) * 100\n",
    "    memory = part_func().memory_usage().sum()\n",
    "    return min_time, memory\n",
    "\n",
    "\n",
    "def experiment_maker(\n",
    "    dataset: list[list], func: callable, parameters: dict[str:list]\n",
    ") -> pd.DataFrame:\n",
    "    results = list()\n",
    "    max_len = np.prod([len(item) for item in parameters.values()])\n",
    "    for item in tqdm(itertools.product(*parameters.values()), total=max_len):\n",
    "        data = encode_data(dataset, sparse=item[3])\n",
    "        avg, memory = run_and_time(\n",
    "            func,\n",
    "            item[1],\n",
    "            item[2],\n",
    "            {\"df\": data, \"min_support\": item[0], \"use_colnames\": item[4]},\n",
    "        )\n",
    "        results.append(\n",
    "            [\n",
    "                *item,\n",
    "                avg,\n",
    "                data.memory_usage().sum(),\n",
    "                memory,\n",
    "            ]\n",
    "        )\n",
    "    run_resultnames = [\"min_time [ms]\", \"memory_encoding\", \"memory_itemsets\"]\n",
    "    df_colnames = list(parameters.keys()) + run_resultnames\n",
    "    return pd.DataFrame(results, columns=df_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c02c81-9e08-401a-8dc7-39b9ed1e8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "data1_params_sparse = {\n",
    "    \"min_supports\": [0.2, 0.4, 0.6, 0.8],\n",
    "    \"measurements\": [10],\n",
    "    \"executions\": [10],\n",
    "    \"sparse\": [False, True],\n",
    "    \"colnames\": [False],\n",
    "}\n",
    "data2_params_sparse = {\n",
    "    \"min_supports\": [0.002, 0.004, 0.008, 0.016, 0.032, 0.064],\n",
    "    \"measurements\": [10],\n",
    "    \"executions\": [1],\n",
    "    \"sparse\": [False, True],\n",
    "    \"colnames\": [False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb529233-7b34-4006-97d3-502749a53fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_1_apri = experiment_maker(dataset1, apriori, data1_params_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39176df2-9afa-46db-ba17-c4b67cd2e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_2_apri = experiment_maker(dataset2, apriori, data2_params_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaea535-e63a-4e28-abdd-09756b3dd9bf",
   "metadata": {},
   "source": [
    "### 4.2. Display results on each dataset in a separate, suitable table (create useful columns), focussing on the comparison of runtime and memory consumption for executions on non-sparse and sparse data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76fa05c-5555-4051-abbf-2becea8ee2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1_apri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a2e0e-b1df-434a-bb25-0d245f13e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2_apri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7792f9e7-0db4-49c1-824e-f477981994b6",
   "metadata": {},
   "source": [
    "### 4.3. Interpret the results ‚Äì state observations, limitations, advice regarding the use of sparse representations!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb13e55-5c4d-4eaa-a604-165626d6f3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6895368a-b904-4369-8553-db65b77815eb",
   "metadata": {},
   "source": [
    "### 4.4. Explain, why only the minimum runtime is reported (in contrast to other options, like the average runtime).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658253bb-8fd3-4406-8005-cc562ac348ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dbc978b-f510-4c9b-b11a-075baa281a18",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ex5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739560c-68d9-4117-bfc4-d3bf2d7cd4ca",
   "metadata": {},
   "source": [
    "## 5. Exercise\n",
    "\n",
    "### 5.1. Time and run APRIORI and FP-Growth on both datasets.\n",
    " - For the grocery dataset use 0.2, 0.4, 0.6, 0.8 as the support thresholds, run 10 measurements for each setting and use 10 executions for each repetition, and\n",
    " - for the T10I4D100K dataset use 0.002, 0.004, 0.008, 0.016, 0.032, 0.064 as the support thresholds, run 10 measurements for each setting and use 1 execution for each repetition.\n",
    "\n",
    "Out of the 10 measurements, report only the minimum for each setting (column parameter and\n",
    "support threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f7197-b27a-478e-8c45-5ea8396abe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "data1_params = {\n",
    "    \"min_supports\": [0.2, 0.4, 0.6, 0.8],\n",
    "    \"measurements\": [10],\n",
    "    \"executions\": [10],\n",
    "    \"sparse\": [False],\n",
    "    \"colnames\": [False],\n",
    "}\n",
    "data2_params = {\n",
    "    \"min_supports\": [0.002, 0.004, 0.008, 0.016, 0.032, 0.064],\n",
    "    \"measurements\": [10],\n",
    "    \"executions\": [1],\n",
    "    \"sparse\": [False],\n",
    "    \"colnames\": [False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119fc6f-5e76-418e-861e-d483cc7cc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_dict = {\"apriori\": apriori, \"fpgrowth\": fpgrowth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed6632-c528-4f43-927a-8874af7d5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_1 = list()\n",
    "for key, func in algo_dict.items():\n",
    "    _df = experiment_maker(dataset1, func, data1_params)\n",
    "    _df[\"Algorithm\"] = key\n",
    "    res_1.append(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8146ed-8f84-4b28-ad56-53cbf75a4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_2 = list()\n",
    "for key, func in algo_dict.items():\n",
    "    _df = experiment_maker(dataset2, func, data2_params)\n",
    "    _df[\"Algorithm\"] = key\n",
    "    res_2.append(_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df876ef-173f-4102-add8-b660a7ef7f7c",
   "metadata": {},
   "source": [
    "### 5.2.Display results on each dataset in a separate, suitable table (create useful columns), focussing on the comparison of runtime for executions of the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69809a4-4324-4e07-82cb-14666bb5ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = pd.concat(res_1)\n",
    "table_1.columns = table_1.columns.str.capitalize()\n",
    "table_1[[\"Algorithm\", \"Min_supports\", \"Min_time [ms]\", \"Memory_encoding\", \"Memory_itemsets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38747c74-4c30-4952-be1e-22d232a8924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2 = pd.concat(res_2)\n",
    "table_2.columns = table_2.columns.str.capitalize()\n",
    "table_2[[\"Algorithm\", \"Min_supports\", \"Min_time [ms]\", \"Memory_encoding\", \"Memory_itemsets\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad40be4-5c67-4d52-baf1-9b6fbf9355cf",
   "metadata": {},
   "source": [
    "### 5.3. Add a visual comparison by plotting the runtimes of both algorithms against the support thresholds into the same diagram (thus, one diagram per dataset). Use scaled axes where useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6cb3b-a21e-4749-b69d-bec3db5947fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.lineplot(data=table_1, x=\"Min_supports\", y=\"Min_time [ms]\", hue=\"Algorithm\")\n",
    "ax.set(\n",
    "    xlabel=\"Support Thresholds\",\n",
    "    ylabel=\"Minimum runtime [ms]\",\n",
    "    title=\"Runtime comparison of 'Apriori' and 'fpgrowth' algorithm for different supports\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e5684-cbdc-4093-8bdc-ef75cb315b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.lineplot(data=table_2, x=\"Min_supports\", y=\"Min_time [ms]\", hue=\"Algorithm\")\n",
    "ax.set(\n",
    "    xlabel=\"Support Thresholds\",\n",
    "    ylabel=\"Minimum runtime [ms]\",\n",
    "    title=\"Runtime comparison of 'Apriori' and 'fpgrowth' algorithm for different supports\",\n",
    ")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a67e98e-934d-4bc6-ad54-67c07f553fc3",
   "metadata": {},
   "source": [
    "### 5.4.  Interpret the results ‚Äì state observations, limitations, advice regarding the use of the two algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa43cc-421a-422f-b908-faed8131866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1.to_parquet(os.path.join(path_to_data, \"table_1.parquet\"), engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d26e19-b6c7-41cf-bd98-7b0adfd8c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2.to_parquet(os.path.join(path_to_data, \"table_2.parquet\"), engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbadb09-3df0-44c0-8b05-4da97c228cb6",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ref'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0230c-c730-459d-8091-df1715975467",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<p> [1] http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036044d-4c18-4711-811a-75cf63dc3e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EMDM",
   "language": "python",
   "name": "emdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
